{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d78818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import datetime\n",
    "import requests\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7807f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3aa79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfdebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab3d71a2b4f411f88e8a693aebc5f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load FAQs\n",
    "with open('faq.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "documents = [f\"Q: {item['question']}\\nA: {item['answer']}\" for item in data]\n",
    "metadatas = [{\"question\": item[\"question\"]} for item in data]\n",
    "\n",
    "# Embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedder.encode(documents, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_faq\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"faq\")\n",
    "\n",
    "if len(collection.get()['ids']) == 0:\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        embeddings=embeddings.tolist(),\n",
    "        metadatas=metadatas,\n",
    "        ids=[str(i) for i in range(len(documents))]\n",
    "    )\n",
    "\n",
    "# Load Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(history=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0d92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757dbaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Emotion Detection Model\n",
    "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "def detect_emotion(text):\n",
    "    emotions = emotion_classifier(text)[0]\n",
    "    top_emotion = max(emotions, key=lambda x: x['score'])\n",
    "    return top_emotion['label'], top_emotion['score']\n",
    "\n",
    "def add_empathy_to_response(emotion, base_response):\n",
    "    empathy_prefix = {\n",
    "        \"joy\": \"That's wonderful to hear! 😊 \",\n",
    "        \"anger\": \"I'm sorry you're feeling upset. Let's work on this together. \",\n",
    "        \"sadness\": \"I'm here for you. 💙 \", \n",
    "        \"fear\": \"Don't worry, I'm here to help. \",\n",
    "        \"surprise\": \"That's interesting! \",\n",
    "        \"neutral\": \"\"\n",
    "    }\n",
    "    return empathy_prefix.get(emotion, \"\") + base_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gemini_answer(query, k=3, similarity_threshold=0.6):\n",
    "    query_embedding = embedder.encode([query])[0]\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=k)\n",
    "\n",
    "    if not results['documents'][0] or len(results['documents'][0]) == 0:\n",
    "        return None, 0.0  # Return None with low confidence\n",
    "\n",
    "    context = \"\\n\\n\".join(results['documents'][0])\n",
    "    \n",
    "    emotion, _ = detect_emotion(query)\n",
    "    prompt = f\"\"\"You are a helpful and emotionally aware assistant. The user appears to be feeling {emotion} based on the query. Respond with professionalism, empathy, and clarity.\n",
    "\n",
    "        If the emotion is 'anger', gently acknowledge their frustration and offer to escalate the issue by asking if they'd like to raise a support ticket.\n",
    "        Dont use emojis.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "        Answer:\"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    avg_score = 1 - sum(results['distances'][0]) / len(results['distances'][0])\n",
    "    return response.text, avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def notify_human_agent(session_id, user_input):\n",
    "    payload = {\n",
    "        \"session_id\": session_id,\n",
    "        \"message\": user_input,\n",
    "        \"status\": \"escalation_triggered\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"https://your-agent-alert-endpoint.com/notify\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Bot: Human agent has been notified successfully.\")\n",
    "        else:\n",
    "            print(\"Bot: Failed to notify human agent.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Bot: Notification failed due to: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_csat_feedback(summary_text):\n",
    "    try:\n",
    "        rating_input = input(\"Please rate your experience with this chat (1-5): \").strip()\n",
    "        text_feedback = input(\"Optional: Share any comments about your experience: \").strip()\n",
    "\n",
    "        if rating_input == \"\":\n",
    "            raise ValueError(\"No rating provided\")\n",
    "\n",
    "        rating = int(rating_input)\n",
    "        return rating, text_feedback or \"No comment provided by user.\"\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"No valid CSAT rating provided. Generating CSAT from summary...\")\n",
    "\n",
    "        auto_eval_prompt = f\"\"\"\n",
    "        Based on the following chat summary, give a customer satisfaction score between 1 (very bad) and 5 (excellent).\n",
    "        Also provide a short comment representing what a typical user might feel.\n",
    "\n",
    "        Summary:\n",
    "        {summary_text}\n",
    "\n",
    "        Return response in the following format:\n",
    "        Rating: <number>\n",
    "        Comment: <generated comment>\n",
    "        \"\"\"\n",
    "\n",
    "        auto_response = model.generate_content(auto_eval_prompt).text.strip()\n",
    "\n",
    "        # Extracting score and comment\n",
    "        lines = auto_response.splitlines()\n",
    "        rating_line = next((line for line in lines if line.lower().startswith(\"rating:\")), \"Rating: 3\")\n",
    "        comment_line = next((line for line in lines if line.lower().startswith(\"comment:\")), \"Comment: Not bad.\")\n",
    "\n",
    "        try:\n",
    "            rating = int(rating_line.split(\":\")[1].strip())\n",
    "        except:\n",
    "            rating = 3\n",
    "\n",
    "        comment = comment_line.split(\":\", 1)[1].strip() if \":\" in comment_line else \"No comment.\"\n",
    "        return rating, comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CHAT SESSION\n",
    "session_id = str(uuid.uuid4())\n",
    "session_start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "chat_history_log = []\n",
    "CONFIDENCE_THRESHOLD = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Gemini EQ Chatbot (Session ID: 797a9cd1-b55a-43e0-8b88-10b8979985cc) - Type 'exit' to quit\n",
      "Bot (EQ-RAG): To provide you with your order summary, I need more information.  Could you please provide your order number or the email address associated with your order?  This will allow me to access your order details and provide you with the information you need.\n",
      "\n",
      "Bot (EQ-RAG): A:  We strive to provide accurate and timely information.  Is there anything else I can help you with today?\n",
      "\n",
      "Bot (EQ-RAG): I understand your frustration and disappointment that your question wasn't answered to your satisfaction.  I apologize for that.  Could you please rephrase your question or provide more details about what you were hoping to learn?  The more information you can give me, the better I can assist you.\n",
      "\n",
      "Bot (EQ-RAG): I understand your frustration.  It sounds like you're feeling angry, and I apologize if my previous responses haven't adequately addressed your needs.  Could you please tell me more about what's making you upset?  Perhaps clarifying the specific issue will help me assist you better.\n",
      "\n",
      "If you'd prefer to escalate this, I'm happy to open a support ticket for you to allow a specialist to investigate further. Would you like me to do so?\n",
      "\n",
      "Bot (EQ-RAG): We're happy to help ensure your packages arrive safely and efficiently.  Is there anything else I can assist you with today?\n",
      "\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(f\"🤖 Gemini EQ Chatbot (Session ID: {session_id}) - Type 'exit' to quit\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    emotion, confidence = detect_emotion(user_input)\n",
    "    chat_history_log.append(f\"User: {user_input} [Emotion: {emotion} ({confidence:.2f})]\")\n",
    "\n",
    "    rag_response, confidence_score = generate_gemini_answer(user_input)\n",
    "\n",
    "    if rag_response:\n",
    "        empathetic_response = add_empathy_to_response(emotion, rag_response)\n",
    "        print(\"Bot (EQ-RAG):\", rag_response)\n",
    "        chat_history_log.append(f\"Bot (EQ-RAG): {empathetic_response} [Confidence: {confidence_score:.2f}]\")\n",
    "    else:\n",
    "        print(\"Bot: I'm not confident in my answer. Escalating to a human agent... 🧑‍💼\")\n",
    "        chat_history_log.append(\"Bot: Escalation triggered due to no response.\")\n",
    "        notify_human_agent(session_id, user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3133d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save chat history\n",
    "with open(f\"chat_history_{session_id}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Session ID: {session_id}\\nStart Time: {session_start_time}\\n\\n\")\n",
    "    for line in chat_history_log:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d383836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize chat\n",
    "with open(f\"chat_history_{session_id}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chat_text = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid CSAT rating provided. Generating CSAT from summary...\n",
      "Thank you for your feedback! You rated this chat: 2/5\n",
      "Your comment: Completely unhelpful and frustrating.  The bot couldn't even track my order, and then made a bizarre and irrelevant response. I'm glad I could escalate to a human, but the whole experience was a waste of time.\n"
     ]
    }
   ],
   "source": [
    "csat_rating, csat_comment = ask_csat_feedback(summary_response.text)\n",
    "print(f\"Thank you for your feedback! You rated this chat: {csat_rating}/5\")\n",
    "if csat_comment:\n",
    "    print(f\"Your comment: {csat_comment}\")\n",
    "\n",
    "with open(f\"csat_{session_id}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Session ID: {session_id}\\nCSAT Rating: {csat_rating}\\nComment: {csat_comment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096923c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588e55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exoplanet_prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
