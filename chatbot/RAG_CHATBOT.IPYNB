{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c325c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce84e0092f6493484c60a7904515081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Integrated Gemini Chatbot with RAG (type 'exit' to quit)\n",
      "Bot (RAG): Hi there! How can I help you today?\n",
      "\n",
      "Bot (RAG): The provided text focuses on shipping and delivery options.  There is no information about singing capabilities.  Therefore, the answer is **no**.\n",
      "\n",
      "Bot (RAG): We offer standard, expedited, and express shipping through FedEx, UPS, and USPS.  Free standard shipping is available on orders over $50 within the continental U.S.  However, some items (batteries, aerosols, perishables) may have shipping restrictions.\n",
      "\n",
      "Bot (RAG): No, you cannot ship children.  Shipping children is illegal and incredibly dangerous.\n",
      "\n",
      "Bot (RAG): Based on the provided text, you can ship most items, but there are restrictions on batteries, aerosols, and perishables.  The exact restrictions aren't detailed.  To know for sure if a specific item is shippable, you would need to check with the company directly or review their shipping policy.\n",
      "\n",
      "Bot (RAG): You're welcome!  Is there anything else I can help you with?\n",
      "\n",
      "Bot (RAG): The provided context gives answers to questions about shipping delays, combining orders, and rerouting packages.  There is no question in the context that has \"no\" as an answer.  Therefore, there is no answer to provide.\n",
      "\n",
      "Bot: Goodbye!\n",
      "\n",
      "Summary:\n",
      " The user initially asked the bot to sing, then inquired about shipping options.  The bot explained its shipping options (standard, expedited, express), noting restrictions on certain items.  Crucially, the bot clarified that shipping children is illegal.  The conversation ended with the user expressing satisfaction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Load FAQ data\n",
    "with open('faq.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "documents = [f\"Q: {item['question']}\\nA: {item['answer']}\" for item in data]\n",
    "metadatas = [{\"question\": item[\"question\"]} for item in data]\n",
    "\n",
    "# Generate vector embeddings\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedder.encode(documents, show_progress_bar=True)\n",
    "\n",
    "# Setup ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_faq\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"faq\")\n",
    "\n",
    "if len(collection.get()['ids']) == 0:\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        embeddings=embeddings.tolist(),\n",
    "        metadatas=metadatas,\n",
    "        ids=[str(i) for i in range(len(documents))]\n",
    "    )\n",
    "\n",
    "# Initialize Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "def generate_gemini_answer(query, k=3, similarity_threshold=0.6):\n",
    "    try:\n",
    "        query_embedding = embedder.encode([query])[0]\n",
    "        results = collection.query(query_embeddings=[query_embedding], n_results=10)\n",
    "\n",
    "        if not results.get(\"documents\") or not results[\"documents\"][0]:\n",
    "            return \"I'm sorry, I couldn't find any relevant information to answer your question.\"\n",
    "\n",
    "        # Filter based on similarity threshold\n",
    "        docs_scores = zip(results[\"documents\"][0], results[\"distances\"][0])\n",
    "        filtered = [(doc, score) for doc, score in docs_scores if score < (1 - similarity_threshold)]\n",
    "\n",
    "        if not filtered:\n",
    "            return \"I'm sorry, I couldn't find any relevant information to answer your question.\"\n",
    "\n",
    "        context = \"\\n\\n\".join([doc for doc, _ in filtered[:k]])\n",
    "\n",
    "        prompt = f\"\"\"Answer the following question based on the context provided.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while generating the answer: {str(e)}\"\n",
    "\n",
    "# CHATBOT STARTS HERE\n",
    "\n",
    "chat_history_log = []\n",
    "\n",
    "print(\"ðŸ¤– Integrated Gemini Chatbot with RAG (type 'exit' to quit)\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    chat_history_log.append(f\"{timestamp} | User: {user_input}\")\n",
    "\n",
    "    rag_response = generate_gemini_answer(user_input)\n",
    "    if rag_response:\n",
    "        print(\"Bot (RAG):\", rag_response)\n",
    "        chat_history_log.append(f\"{timestamp} | Bot (RAG): {rag_response}\")\n",
    "    else:\n",
    "        response = chat.send_message(user_input)\n",
    "        print(\"Bot:\", response.text)\n",
    "        chat_history_log.append(f\"{timestamp} | Bot: {response.text}\")\n",
    "\n",
    "# Save chat history\n",
    "with open(\"chat_history.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in chat_history_log:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "# Summarize and save the conversation\n",
    "with open(\"chat_history.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chat_text = f.read()\n",
    "\n",
    "summary_prompt = f\"Summarize the following conversation briefly:\\n\\n{chat_text}\"\n",
    "summary_response = model.generate_content(summary_prompt)\n",
    "print(\"\\nSummary:\\n\", summary_response.text)\n",
    "\n",
    "summary_filename = f\"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "with open(summary_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exoplanet_prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
